# Simons AI - Hybrid Orchestrator Configuration
# Copy to .env and fill in your values

# =============================================================================
# GEMINI API (FAST mode - cloud inference)
# =============================================================================
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
LLM_DEBUG=false
LLM_LOG_LEVEL=INFO

# Default inference mode: auto, fast, deep
LLM_DEFAULT_MODE=auto

# =============================================================================
# SERVER SETTINGS
# =============================================================================
LLM_HOST=0.0.0.0
LLM_PORT=8000

# CORS (comma-separated origins, or * for all)
LLM_CORS_ORIGINS=*

# =============================================================================
# OLLAMA SETTINGS (DEEP mode - local GPU inference)
# =============================================================================
LLM_OLLAMA_BASE_URL=http://localhost:11434
LLM_OLLAMA_TIMEOUT_SECONDS=120

# Model defaults (for warmup)
LLM_DEFAULT_PROFILE=qwen
LLM_WARMUP_ON_STARTUP=false
LLM_WARMUP_PROFILE=qwen
